{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_food_review-approach_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M82rKOSArHTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "34e0505c-0399-4f54-e632-3696e6762fc3"
      },
      "source": [
        "pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/86/c3dcb600b4f9e7584ed90ea9d30a717fb5c0111574675f442c3e7bc19535/catboost-0.24.1-cp36-none-manylinux1_x86_64.whl (66.1MB)\n",
            "\u001b[K     |████████████████████████████████| 66.1MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BXOWvCIgvGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#Importing Required Libraries\n",
        "#_______________________________________________________________________________________________________________\n",
        "import numpy as np\n",
        "import gc\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style # for styling the graphs\n",
        "# style.available (to know the available list of styles)\n",
        "style.use('ggplot') # chosen style\n",
        "plt.rc('xtick',labelsize=13) # to globally set the tick size\n",
        "plt.rc('ytick',labelsize=13) # to globally set the tick size\n",
        "\n",
        "# To print multiple outputs together\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "# Change column display number during print\n",
        "pd.set_option('display.max_columns', 500)\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# To display float with 2 decimal, avoid scientific printing\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "from keras.layers import BatchNormalization\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6Ouf_IKhyJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "cc15760c-e485-4204-b5ef-c041f4dfb933"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/4AGs33NyDz6Ghs6mgPcBMmi90UAi-VignAIIghyyGzJIogB4SOR0hyA\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YsPbOIgiBJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "59e48be5-831a-4fc9-bd54-114255e1147a"
      },
      "source": [
        "#train data\n",
        "path='/content/gdrive/My Drive/Amazon_fine_reviews/New_train.csv'\n",
        "train=pd.read_csv(path)\n",
        "train.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>Summary</th>\n",
              "      <th>count_adj</th>\n",
              "      <th>count_noun</th>\n",
              "      <th>count_adv</th>\n",
              "      <th>count_verb</th>\n",
              "      <th>pronoun</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I bought these from a large chain pet store. a...</td>\n",
              "      <td>1</td>\n",
              "      <td>do not buy</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This soup is incredibly good!  But honestly, I...</td>\n",
              "      <td>5</td>\n",
              "      <td>Really great taste! Price should be less though.</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Our family loves these tasty and healthy sesam...</td>\n",
              "      <td>5</td>\n",
              "      <td>Tasty and Healthy Snack</td>\n",
              "      <td>13</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The local auto shop offers this free to it cus...</td>\n",
              "      <td>4</td>\n",
              "      <td>Quick, Easy and Tasty</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I brought 2 bottles.  One I carry in my pocket...</td>\n",
              "      <td>5</td>\n",
              "      <td>Love it!!</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Score  \\\n",
              "0  I bought these from a large chain pet store. a...      1   \n",
              "1  This soup is incredibly good!  But honestly, I...      5   \n",
              "2  Our family loves these tasty and healthy sesam...      5   \n",
              "3  The local auto shop offers this free to it cus...      4   \n",
              "4  I brought 2 bottles.  One I carry in my pocket...      5   \n",
              "\n",
              "                                            Summary  count_adj  count_noun  \\\n",
              "0                                        do not buy          2           8   \n",
              "1  Really great taste! Price should be less though.          7          13   \n",
              "2                           Tasty and Healthy Snack         13          45   \n",
              "3                             Quick, Easy and Tasty          2           6   \n",
              "4                                         Love it!!          3          13   \n",
              "\n",
              "   count_adv  count_verb  pronoun  \n",
              "0          2           8        5  \n",
              "1          5          12        7  \n",
              "2          1          19        9  \n",
              "3          4           8        8  \n",
              "4          3           5        6  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hgSqE05jm0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cc3b92a-4ebd-4d19-ea4e-13d72959db3d"
      },
      "source": [
        "train['Text'].iloc[16]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'If you lack dark green vegetables this will substitute.  You must add flavor and a starchy dish to accompany it.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQkkytrIkxMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "ba9262bc-3d44-4d08-b537-cc6141b06781"
      },
      "source": [
        "#train data\n",
        "path='/content/gdrive/My Drive/Amazon_fine_reviews/New_test.csv'\n",
        "test=pd.read_csv(path)\n",
        "test.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "      <th>count_adj</th>\n",
              "      <th>count_adv</th>\n",
              "      <th>count_verb</th>\n",
              "      <th>pronoun</th>\n",
              "      <th>noun</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This oatmeal is not good. Its mushy, soft, I d...</td>\n",
              "      <td>Don't like it</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Buyer Beware Please! This sweetener is not for...</td>\n",
              "      <td>Warning!  WARNING!  -ALCOHOL SUGARS!</td>\n",
              "      <td>35</td>\n",
              "      <td>20</td>\n",
              "      <td>55</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Five minutes in, one tentacle was bitten off, ...</td>\n",
              "      <td>Sad outcome</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kettle chips now look, feel and taste like Lay...</td>\n",
              "      <td>Surprise 1  It's different...</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>These chips are greasy and taste burnt-there i...</td>\n",
              "      <td>Chips</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  \\\n",
              "0  This oatmeal is not good. Its mushy, soft, I d...   \n",
              "1  Buyer Beware Please! This sweetener is not for...   \n",
              "2  Five minutes in, one tentacle was bitten off, ...   \n",
              "3  Kettle chips now look, feel and taste like Lay...   \n",
              "4  These chips are greasy and taste burnt-there i...   \n",
              "\n",
              "                                Summary  count_adj  count_adv  count_verb  \\\n",
              "0                         Don't like it          2          2           5   \n",
              "1  Warning!  WARNING!  -ALCOHOL SUGARS!         35         20          55   \n",
              "2                           Sad outcome          1          4           6   \n",
              "3         Surprise 1  It's different...          3          5           4   \n",
              "4                                 Chips          5          3           7   \n",
              "\n",
              "   pronoun  noun  \n",
              "0        3     3  \n",
              "1       33    33  \n",
              "2        0     0  \n",
              "3        3     3  \n",
              "4        3     3  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB10NVJ8tVJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "37ad0d5c-f1cf-4d89-8eef-5cca4805fdc2"
      },
      "source": [
        "#Wordcloud\n",
        "!pip install wordcloud"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bJ4UU2ftfut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq07AxiIoLm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e75002c3-6b5e-4790-ca8f-44bb0edd7262"
      },
      "source": [
        "''' from wordcloud import WordCloud,STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "train_pos = train[train['Score']==1]\n",
        "train_pos = train_pos['Summary']\n",
        "\n",
        "def wordcloud_draw(data, color = 'black'):\n",
        "    words = ' '.join(data)\n",
        "    cleaned_word = \" \".join([word for word in words.split()\n",
        "                            if 'http' not in word\n",
        "                                and not word.startswith('@')\n",
        "                                and not word.startswith('#')\n",
        "                                and word != 'RT'\n",
        "                            ])\n",
        "    wordcloud = WordCloud(stopwords=STOPWORDS,\n",
        "                      background_color=color,\n",
        "                      width=2500,\n",
        "                      height=2000\n",
        "                     ).generate(cleaned_word)\n",
        "    plt.figure(1,figsize=(13, 13))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "print(\"Score 1 summary words\")\n",
        "wordcloud_draw(train_pos,'white') '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' from wordcloud import WordCloud,STOPWORDS\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nsns.set(style=\"darkgrid\")\\ntrain_pos = train[train[\\'Score\\']==1]\\ntrain_pos = train_pos[\\'Summary\\']\\n\\ndef wordcloud_draw(data, color = \\'black\\'):\\n    words = \\' \\'.join(data)\\n    cleaned_word = \" \".join([word for word in words.split()\\n                            if \\'http\\' not in word\\n                                and not word.startswith(\\'@\\')\\n                                and not word.startswith(\\'#\\')\\n                                and word != \\'RT\\'\\n                            ])\\n    wordcloud = WordCloud(stopwords=STOPWORDS,\\n                      background_color=color,\\n                      width=2500,\\n                      height=2000\\n                     ).generate(cleaned_word)\\n    plt.figure(1,figsize=(13, 13))\\n    plt.imshow(wordcloud)\\n    plt.axis(\\'off\\')\\n    plt.show()\\n    \\nprint(\"Score 1 summary words\")\\nwordcloud_draw(train_pos,\\'white\\') '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cQl-Q72u6e-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "e5308ecb-598e-4f26-9cea-f2477d1fc72b"
      },
      "source": [
        "''' train_pos = train[train['Score']==3]\n",
        "train_pos = train_pos['Summary']\n",
        "\n",
        "def wordcloud_draw(data, color = 'black'):\n",
        "    words = ' '.join(data)\n",
        "    cleaned_word = \" \".join([word for word in words.split()\n",
        "                            if 'http' not in word\n",
        "                                and not word.startswith('@')\n",
        "                                and not word.startswith('#')\n",
        "                                and word != 'RT'\n",
        "                            ])\n",
        "    wordcloud = WordCloud(stopwords=STOPWORDS,\n",
        "                      background_color=color,\n",
        "                      width=2500,\n",
        "                      height=2000\n",
        "                     ).generate(cleaned_word)\n",
        "    plt.figure(1,figsize=(13, 13))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "print(\"Score 1 summary words\")\n",
        "wordcloud_draw(train_pos,'white') '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' train_pos = train[train[\\'Score\\']==3]\\ntrain_pos = train_pos[\\'Summary\\']\\n\\ndef wordcloud_draw(data, color = \\'black\\'):\\n    words = \\' \\'.join(data)\\n    cleaned_word = \" \".join([word for word in words.split()\\n                            if \\'http\\' not in word\\n                                and not word.startswith(\\'@\\')\\n                                and not word.startswith(\\'#\\')\\n                                and word != \\'RT\\'\\n                            ])\\n    wordcloud = WordCloud(stopwords=STOPWORDS,\\n                      background_color=color,\\n                      width=2500,\\n                      height=2000\\n                     ).generate(cleaned_word)\\n    plt.figure(1,figsize=(13, 13))\\n    plt.imshow(wordcloud)\\n    plt.axis(\\'off\\')\\n    plt.show()\\n    \\nprint(\"Score 1 summary words\")\\nwordcloud_draw(train_pos,\\'white\\') '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Kj25ZtvcJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "9a2ed0cb-e720-4387-e228-bc81321bac94"
      },
      "source": [
        "''' train_pos = train[train['Score']==4]\n",
        "train_pos = train_pos['Summary']\n",
        "\n",
        "def wordcloud_draw(data, color = 'black'):\n",
        "    words = ' '.join(data)\n",
        "    cleaned_word = \" \".join([word for word in words.split()\n",
        "                            if 'http' not in word\n",
        "                                and not word.startswith('@')\n",
        "                                and not word.startswith('#')\n",
        "                                and word != 'RT'\n",
        "                            ])\n",
        "    wordcloud = WordCloud(stopwords=STOPWORDS,\n",
        "                      background_color=color,\n",
        "                      width=2500,\n",
        "                      height=2000\n",
        "                     ).generate(cleaned_word)\n",
        "    plt.figure(1,figsize=(13, 13))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "print(\"Score 4 summary words\")\n",
        "wordcloud_draw(train_pos,'white') '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' train_pos = train[train[\\'Score\\']==4]\\ntrain_pos = train_pos[\\'Summary\\']\\n\\ndef wordcloud_draw(data, color = \\'black\\'):\\n    words = \\' \\'.join(data)\\n    cleaned_word = \" \".join([word for word in words.split()\\n                            if \\'http\\' not in word\\n                                and not word.startswith(\\'@\\')\\n                                and not word.startswith(\\'#\\')\\n                                and word != \\'RT\\'\\n                            ])\\n    wordcloud = WordCloud(stopwords=STOPWORDS,\\n                      background_color=color,\\n                      width=2500,\\n                      height=2000\\n                     ).generate(cleaned_word)\\n    plt.figure(1,figsize=(13, 13))\\n    plt.imshow(wordcloud)\\n    plt.axis(\\'off\\')\\n    plt.show()\\n    \\nprint(\"Score 4 summary words\")\\nwordcloud_draw(train_pos,\\'white\\') '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy0NVbTbv_GT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "31acc5d3-63ba-46b6-8fa3-e9208f0d22aa"
      },
      "source": [
        "''' train_pos = train[train['Score']==5]\n",
        "train_pos = train_pos['Summary']\n",
        "\n",
        "def wordcloud_draw(data, color = 'black'):\n",
        "    words = ' '.join(data)\n",
        "    cleaned_word = \" \".join([word for word in words.split()\n",
        "                            if 'http' not in word\n",
        "                                and not word.startswith('@')\n",
        "                                and not word.startswith('#')\n",
        "                                and word != 'RT'\n",
        "                            ])\n",
        "    wordcloud = WordCloud(stopwords=STOPWORDS,\n",
        "                      background_color=color,\n",
        "                      width=2500,\n",
        "                      height=2000\n",
        "                     ).generate(cleaned_word)\n",
        "    plt.figure(1,figsize=(13, 13))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "print(\"Score 4 summary words\")\n",
        "wordcloud_draw(train_pos,'white') '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' train_pos = train[train[\\'Score\\']==5]\\ntrain_pos = train_pos[\\'Summary\\']\\n\\ndef wordcloud_draw(data, color = \\'black\\'):\\n    words = \\' \\'.join(data)\\n    cleaned_word = \" \".join([word for word in words.split()\\n                            if \\'http\\' not in word\\n                                and not word.startswith(\\'@\\')\\n                                and not word.startswith(\\'#\\')\\n                                and word != \\'RT\\'\\n                            ])\\n    wordcloud = WordCloud(stopwords=STOPWORDS,\\n                      background_color=color,\\n                      width=2500,\\n                      height=2000\\n                     ).generate(cleaned_word)\\n    plt.figure(1,figsize=(13, 13))\\n    plt.imshow(wordcloud)\\n    plt.axis(\\'off\\')\\n    plt.show()\\n    \\nprint(\"Score 4 summary words\")\\nwordcloud_draw(train_pos,\\'white\\') '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kToBwHiswLmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "57d6306c-df73-4996-fef5-6d0755ca9d27"
      },
      "source": [
        "''' max_len=max([len(s.split()) for s in train['Text']]) '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" max_len=max([len(s.split()) for s in train['Text']]) \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLXqTVtYxfeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train['Text']=train['Text'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mo1tFj0yP9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import nltk\n",
        "#nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEzN3ggLyYkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "93eafb22-98e3-4720-ff79-326427580c8f"
      },
      "source": [
        "#import nltk\n",
        "#nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRAspGhvyiXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14cdb17d-ebc7-46c1-ec71-3620fb1eb70e"
      },
      "source": [
        "#pip install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y8Lutel0rEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "f658c908-07a0-4f36-bac6-1f7f1d8df0d2"
      },
      "source": [
        "''' import re\n",
        "import re\n",
        "import string\n",
        "import os\n",
        "import emoji\n",
        "import textblob\n",
        "from pprint import pprint\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"darkgrid\")\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "pos_family = {\n",
        "                        'noun' : ['NN','NNS','NNP','NNPS'],\n",
        "                        'pron' : ['PRP','PRP$','WP','WP$'],\n",
        "                        'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
        "                        'adj' :  ['JJ','JJR','JJS'],\n",
        "                        'adv' : ['RB','RBR','RBS','WRB']\n",
        "                     }\n",
        "\n",
        "def check_pos_tag(x, flag):\n",
        "            cnt = 0\n",
        "            try:\n",
        "                wiki = textblob.TextBlob(x)\n",
        "                for tup in wiki.tags:\n",
        "                    ppo = list(tup)[1]\n",
        "                    if ppo in pos_family[flag]:\n",
        "                        cnt += 1\n",
        "            except:\n",
        "                pass\n",
        "            return cnt\n",
        "train['count_adj'] = train['Text'].apply(lambda x: check_pos_tag(x,'adj')) '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ka9BTCBTN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train['count_noun']=train['Text'].apply(lambda x: check_pos_tag(x,'noun'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGg0p49O2QA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train['count_adv'] = train['Text'].apply(lambda x: check_pos_tag(x,'adv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2YQEqkIEArc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train['count_verb'] = train['Text'].apply(lambda x: check_pos_tag(x,'verb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DIDm2gjO7n9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train['pronoun']= train['Text'].apply(lambda x: check_pos_tag(x,'pron'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyKernzqUPbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test['count_adj'] = test['Text'].apply(lambda x: check_pos_tag(x,'adj'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ma3BVptXKEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test['count_adv'] = test['Text'].apply(lambda x: check_pos_tag(x,'adv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hhMrGteZpNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test['count_verb'] = test['Text'].apply(lambda x: check_pos_tag(x,'verb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIrvIpoWZ8AZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test['pronoun']= test['Text'].apply(lambda x: check_pos_tag(x,'pron'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC8GocKraQnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test['noun']=test['Text'].apply(lambda x: check_pos_tag(x,'pron'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfeEqmyHan90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train.to_csv('/content/gdrive/My Drive/Amazon_fine_reviews/New_train.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hGv8mJqa2sP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test.to_csv('/content/gdrive/My Drive/Amazon_fine_reviews/New_test.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuNqO6mzwnnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "def show_dist(df, col):\n",
        "    print('Descriptive stats for {}'.format(col))\n",
        "    print('-'*(len(col)+22))\n",
        "    print(df.groupby('Score')[col].describe())\n",
        "    bins = np.arange(df[col].min(), df[col].max() + 1)\n",
        "    g = sns.FacetGrid(df, col='Score', size=5, hue='Score')\n",
        "    g = g.map(sns.distplot, col, kde=False, norm_hist=True, bins=bins)\n",
        "    plt.show() '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oil6dSKYxSfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show_dist(train, 'count_adj')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPiTDj9AxtXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show_dist(train, 'count_verb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bagjqOK7gxUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop('Summary',1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIQvRoiGj9m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.drop('Summary',1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BT2lYUMlgfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[\"Text\"] = train[\"Text\"].str.lower()\n",
        "test[\"Text\"] = test[\"Text\"].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EafDBfdFmwBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "PUNCT_TO_REMOVE = string.punctuation\n",
        "def remove_punctuation(text):\n",
        "    \"\"\"custom function to remove the punctuation\"\"\"\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "train[\"Text\"] = train['Text'].apply(lambda text: remove_punctuation(text))\n",
        "test[\"Text\"] = test['Text'].apply(lambda text: remove_punctuation(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pd73MG4ob_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d3400eb0-2edd-4de2-869c-419846f14969"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIe9dQzlm0MG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "def remove_stopwords(text):\n",
        "        stopwords_list = stopwords.words('english')+['link','quot','amp']\n",
        "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
        "        whitelist = [\"n't\", \"not\", \"no\"]\n",
        "        words = text.split() \n",
        "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 2] \n",
        "        return \" \".join(clean_words) \n",
        "\n",
        "train['Text']=train['Text'].apply(lambda text:remove_stopwords(text))\n",
        "\n",
        "test['Text']=test['Text'].apply(lambda text:remove_stopwords(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJWvDGdrhmmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b0ff2cea-0aa6-4161-ff51-01096654c6b2"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNV7m3Tfgy8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "def lemmatize(text):\n",
        "        lemma = WordNetLemmatizer()\n",
        "        words = text.split() \n",
        "        stemmed_words = [lemma.lemmatize(word) for word in words]\n",
        "        return \" \".join(stemmed_words)\n",
        "\n",
        "train['Text']=train['Text'].apply(lambda text:lemmatize(text))\n",
        "\n",
        "\n",
        "test['Text']=test['Text'].apply(lambda text:lemmatize(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNgjDYcaoh91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9cfdd695-5aba-48a7-9575-369f8d431e37"
      },
      "source": [
        "train['Text'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bought large chain pet store reading review checked bag made china threw whole bag away wish would read review first'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEHaOAYSoq6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "0a685481-0e8a-45e8-e177-c7f5b87e6b6f"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>count_adj</th>\n",
              "      <th>count_adv</th>\n",
              "      <th>count_verb</th>\n",
              "      <th>pronoun</th>\n",
              "      <th>noun</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oatmeal not good mushy soft dont like quaker o...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buyer beware please sweetener not everybody ma...</td>\n",
              "      <td>35</td>\n",
              "      <td>20</td>\n",
              "      <td>55</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>five minute one tentacle bitten ball inside cr...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kettle chip look feel taste like lay chip used...</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chip greasy taste burntthere grease bottom bag...</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>order 6pack large dog chicken pill pocket ever...</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>fault not pay attention ordered went jack link...</td>\n",
              "      <td>14</td>\n",
              "      <td>19</td>\n",
              "      <td>41</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>one first cracker tried yes gluten free may wo...</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>product packing box leaking least single serve...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>flavor big easy bold good every third cup over...</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  count_adj  count_adv  \\\n",
              "0    oatmeal not good mushy soft dont like quaker o...          2          2   \n",
              "1    buyer beware please sweetener not everybody ma...         35         20   \n",
              "2    five minute one tentacle bitten ball inside cr...          1          4   \n",
              "3    kettle chip look feel taste like lay chip used...          3          5   \n",
              "4    chip greasy taste burntthere grease bottom bag...          5          3   \n",
              "..                                                 ...        ...        ...   \n",
              "995  order 6pack large dog chicken pill pocket ever...         11         10   \n",
              "996  fault not pay attention ordered went jack link...         14         19   \n",
              "997  one first cracker tried yes gluten free may wo...         12          9   \n",
              "998  product packing box leaking least single serve...          1          1   \n",
              "999  flavor big easy bold good every third cup over...          5          2   \n",
              "\n",
              "     count_verb  pronoun  noun  \n",
              "0             5        3     3  \n",
              "1            55       33    33  \n",
              "2             6        0     0  \n",
              "3             4        3     3  \n",
              "4             7        3     3  \n",
              "..          ...      ...   ...  \n",
              "995          24       16    16  \n",
              "996          41       26    26  \n",
              "997          20       11    11  \n",
              "998           3        2     2  \n",
              "999          11        3     3  \n",
              "\n",
              "[1000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K6wyLHco6SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class TextSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    Use on text columns in the data\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.key]\n",
        "\n",
        "class NumberSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    Use on numeric columns in the data\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[[self.key]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn1gmGV-o_zP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=train.drop(['Score'], axis=1)\n",
        "y=train['Score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgtUSpnapPU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5c72b0f7-7ee0-4986-a8b7-aa40d682fe16"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "text = Pipeline([\n",
        "                ('selector', TextSelector(key='Text')),\n",
        "                ('tfidf',CountVectorizer(ngram_range=(1,3)))])\n",
        "\n",
        "text.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<32400x1855208 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 3899247 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcSIguWPpfE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_noun=Pipeline([\n",
        "             ('selector', NumberSelector(key='count_noun'))            ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "count_verb=Pipeline([\n",
        "             ('selector', NumberSelector(key='count_verb'))            ])\n",
        "\n",
        "\n",
        "\n",
        "count_adj =Pipeline([\n",
        "             ('selector', NumberSelector(key='count_adj'))            ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "count_adv =Pipeline([\n",
        "             ('selector', NumberSelector(key='count_adv'))            ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pronoun =Pipeline([\n",
        "             ('selector', NumberSelector(key='pronoun')) ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSLqQtulqED8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "feats = FeatureUnion([\n",
        "                      ('text',text),('pronoun',pronoun),\n",
        "                      ('count_verb',count_verb),('count_adv',count_adv),\n",
        "                      ('count_noun',count_noun),('count_adj',count_adj)\n",
        "                      \n",
        "                      ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h02OoY-Fqs5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "d70fcd86-727b-48c0-f35f-4fab1d6ea8fe"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import log_loss\n",
        "from xgboost import plot_importance\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf= XGBClassifier(random_state=9,n_estimators=350,objective='multi:softmax', eval_metric='merror')\n",
        "log=LogisticRegression(random_state=9)\n",
        "\n",
        "#model_list = [('cat',clf),('xgb',clf_1)]\n",
        "\n",
        "#voting_clf_soft=VotingClassifier(estimators=model_list,voting='soft')\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier',clf)\n",
        "    \n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "preds = pipeline.predict(X_test)\n",
        "\n",
        "f1_score=f1_score(y_test,preds,average='micro')\n",
        "print('f1 score:',f1_score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('features',\n",
              "                 FeatureUnion(n_jobs=None,\n",
              "                              transformer_list=[('text',\n",
              "                                                 Pipeline(memory=None,\n",
              "                                                          steps=[('selector',\n",
              "                                                                  TextSelector(key='Text')),\n",
              "                                                                 ('tfidf',\n",
              "                                                                  CountVectorizer(analyzer='word',\n",
              "                                                                                  binary=False,\n",
              "                                                                                  decode_error='strict',\n",
              "                                                                                  dtype=<class 'numpy.int64'>,\n",
              "                                                                                  encoding='utf-8',\n",
              "                                                                                  input='content',\n",
              "                                                                                  lowercase=True,\n",
              "                                                                                  max_df=1.0,\n",
              "                                                                                  max_features=None,\n",
              "                                                                                  min_df=1,\n",
              "                                                                                  ngra...\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, eval_metric='merror',\n",
              "                               gamma=0, learning_rate=0.1, max_delta_step=0,\n",
              "                               max_depth=3, min_child_weight=1, missing=None,\n",
              "                               n_estimators=350, n_jobs=1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=9,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.5093827160493827\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}